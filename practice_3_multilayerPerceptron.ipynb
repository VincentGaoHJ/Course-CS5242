{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_3_multilayerPerceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentGaoHJ/Course-CS5242/blob/master/practice_3_multilayerPerceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t--wDFP1sEdg"
      },
      "source": [
        "## Practice 3: Multilayer Networks\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DW7c6fznGFyZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7fb7347-6698-49fa-ad57-e2265e047b79"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# for auto-reloading extenrnal modules\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gYBM8VgFgwp"
      },
      "source": [
        "**Pytorch has a wide variety of datasets that one can leverage. In this tutorial, we will\n",
        "use one such dataset and build a multilayer neural network to fit the data. We will \n",
        "use PyTorch optimizers to perform the optimization process.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oH7W65sq_Z9"
      },
      "source": [
        "Q1. Use the following snippet to get a dataloader from the already available Mnist dataset from \n",
        "PyTorch. Mnist dataset has 60,000 digit images with its corresponding labels.\n",
        "This snippet will download the dataset if not downloaded already and transform each \n",
        "image before returning it. Dataloaders are iterable over a dataset. For further reading follow [pytorch dataloader](https://pytorch.org/docs/stable/data.html)\n",
        "\n",
        "```python\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "traintloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZA4o635FW8M"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]) \n",
        "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Code for the test dataset and data loader\n",
        "testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)\n",
        "\n",
        "# Use the help command to see the dictionary elements, attributes and method of any object\n",
        "# help(trainloader)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmvPROOEHwGY"
      },
      "source": [
        "Q2. Wrap the dataloader with python “iter” class which will give you an iterable object from which you can get new images and labels using .next(). After applying iter, iterate through a few samples, check the shape, the datatype of the image, label tuple that you are getting. Plot some of the images. Also, print the flattened shape of each image. (hint: use .flatten())\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi27wJQitA_m",
        "outputId": "5489ec72-7ea9-4d61-a233-d861228ebb94"
      },
      "source": [
        "print('Dataset: ', trainloader.dataset)\r\n",
        "print('samples per batch: ', trainloader.batch_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset:  Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: /root/.pytorch/MNIST_data/\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "               Normalize(mean=(0.5,), std=(0.5,))\n",
            "           )\n",
            "samples per batch:  64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CroqW1JWr8or",
        "outputId": "0df0217d-9b8f-4fd5-874d-7533c460419a"
      },
      "source": [
        "# Here we are doing some initial analysis of what .next of dataloader returns\r\n",
        "train_iter = iter(trainloader)\r\n",
        "batches, labels = train_iter.next()\r\n",
        "\r\n",
        "# check the shape\r\n",
        "print('Tensor shape: ', batches.shape)\r\n",
        "# the datatype of the image\r\n",
        "print('Datatype of image: ', batches.type)\r\n",
        "# label tuple that you are getting\r\n",
        "print('Label tuple: ', labels)\r\n",
        "# Also, print the flattened shape of each image. (hint: use .flatten())\r\n",
        "print('Flattened shape of each image: ', batches[0].flatten().shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor shape:  torch.Size([64, 1, 28, 28])\n",
            "Datatype of image:  <built-in method type of Tensor object at 0x7f58147f49d8>\n",
            "Label tuple:  tensor([1, 6, 0, 1, 4, 0, 5, 1, 3, 0, 3, 3, 3, 1, 7, 4, 6, 6, 5, 6, 7, 3, 9, 1,\n",
            "        9, 8, 2, 5, 1, 3, 8, 6, 6, 5, 3, 6, 3, 5, 3, 1, 5, 2, 1, 9, 7, 3, 4, 4,\n",
            "        7, 1, 7, 6, 2, 7, 0, 3, 7, 3, 9, 5, 9, 7, 6, 7])\n",
            "Flattened shape of each image:  torch.Size([784])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "KNZUQobdutI5",
        "outputId": "250e8055-b028-47f1-9e6e-b163167cb722"
      },
      "source": [
        "np.random.seed(0)     # We need to set the seed to help in reproducibility of data\r\n",
        "\r\n",
        "length_of_dict_class = 10 # This indicates we have 10 labels corresponding to Mnist dataset\r\n",
        "dict_class = {0:\"zero\", 1:\"one\", 2: \"two\", 3: \"three\", 4:\"four\", 5:\"five\", 6:\"six\", 7:\"seven\", 8:\"eight\", 9:\"nine\"}\r\n",
        "\r\n",
        "# Since we notice the dimension of image is 1 * 28 * 28, this means image is gray scale, \r\n",
        "# it has only one channel, we should squeeze the extra dimension\r\n",
        "\r\n",
        "\r\n",
        "def visualize_images(examples_per_class):\r\n",
        "    \r\n",
        "    for cls in range(length_of_dict_class):\r\n",
        "        idxs = np.where((labels == cls))[0] # Find index of the specific class\r\n",
        "        # If in this batch we do not get the required number of samples we want to show, skip\r\n",
        "        if len(idxs) >= examples_per_class:\r\n",
        "            idxs = np.random.choice(idxs, examples_per_class, replace=False) \r\n",
        "        \r\n",
        "        # Plot here\r\n",
        "        for enu_idx, img_idx in enumerate(idxs):\r\n",
        "            plt_index = enu_idx * length_of_dict_class + cls + 1\r\n",
        "            plt.subplot(examples_per_class, length_of_dict_class, plt_index)\r\n",
        "            plt.imshow(torch.squeeze(batches[img_idx]))\r\n",
        "            plt.axis('off')\r\n",
        "            if enu_idx == 0:\r\n",
        "                plt.title(dict_class[cls])\r\n",
        "    \r\n",
        "visualize_images(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x576 with 43 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vkEIv5JZH02X"
      },
      "source": [
        "\n",
        "Q3. Build a multilayer neural network with 3 fully connected layers of shape (784, 128), (128, 64) and then (64, 10). Use ReLu activation in between each layer, and at the end of the output layer. \n",
        "The class should have a forward function that you will manually create. The forward will take image batch as an input (image_batch * flattened_image_784_size) and return (image_batch x 10) size vectors.\n",
        "\n",
        "**Hint**: Use torch.nn.Linear for linear layers. Follow this pytorch module to understand how to inherit the [pytorch module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module) class.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIkPZ0nrCBSN",
        "outputId": "0064f3c0-1915-4360-992f-7e926bde3afb"
      },
      "source": [
        "# Declare device which you will be working with\r\n",
        "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\r\n",
        "device"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCBKM8B5H3s2"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    \"\"\"\n",
        "    Multilayer neural network with 3 fully connected layers of shape \n",
        "    (784, 128) -> (128, 64) -> (64, 10)\n",
        "    \"\"\"\n",
        "\n",
        "    # Use ReLu activation in between each layer, and at the end of the output layer. \n",
        "    # The class should have a forward function that you will manually create. \n",
        "    # The forward will take image batch as an input (image_batch * flattened_image_784_size) and return (image_batch x 10) size vectors.\n",
        "    def __init__(self):\n",
        "        # Creates an instance of the base nn.Module class\n",
        "        super(Model, self).__init__() # Inheritance of the base class nn.Module\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(784, 128) # 28 x 28 input pixels connecting to the first hidden layer (128 node)\n",
        "        self.fc2 = nn.Linear(128, 64) # 128 to 64 hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10) # last hidden layer to the output layer (with 10 nodes).\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhhDVNdMH5GM"
      },
      "source": [
        "Q4. Create a cross-entropy loss. You can create it yourself (just like the last tutorial) or create it by using torch.nn.CrossEntropyLoss (pytorch cross-entropy loss uses logits, not softmax probabilities, so we had not applied softmax at the last layer). Initialize an SGD optimizer from torch.optim. \n",
        "\n",
        "**PyTorch Loss-Input Confusion (Cheatsheet)**\n",
        "\n",
        "*   torch.nn.functional.binary_cross_entropy takes logistic sigmoid values as inputs\n",
        "*   torch.nn.functional.binary_cross_entropy_with_logits takes logits as inputs\n",
        "*   torch.nn.functional.cross_entropy takes logits as inputs (performs log_softmax internally)\n",
        "*   torch.nn.functional.nll_loss is like cross_entropy but takes log-probabilities (log-softmax) values as inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Wn9KGV9H8OM",
        "outputId": "d09ec346-742b-4808-829e-b14c7ae75a5c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "network = Model().to(device)\n",
        "print(network)\n",
        "\n",
        "# used 0.1 learning rate\n",
        "learning_rate = 0.1\n",
        "momentum = 0\n",
        "# create a stochastic gradient descent optimizer\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum) \n",
        "# create a loss function\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model(\n",
            "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tuGd0H2H9GD"
      },
      "source": [
        "\n",
        "Q5. (1 pass of the data) Write a training loop which will \n",
        "1.\tGet data batches from dataloader, feed it into the network and get outputs.\n",
        "2.\tGet loss using outputs and ground truth labels.\n",
        "3.\tCall backward on the loss (remember to clear grads before calling gradients)\n",
        "4.\tCall optimizer.step to perform SGD update.\n",
        "5.\tPrint the accuracy, loss and amount of data used till now.\n",
        "\n",
        "\n",
        "**Note**: We have used only training split in this week tutorial for sake of simplicity of the tutorial. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89yBKAZyf98b",
        "outputId": "c4c1d0f0-bcba-49dc-cbc4-033962e157f5"
      },
      "source": [
        "def cal_acc(outputs, labels):\r\n",
        "    # probs: probability that each image is labeled as 1\r\n",
        "    # target: ground truth label\r\n",
        "    correct = 0\r\n",
        "    total = 0\r\n",
        "    with torch.no_grad():\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        total += labels.size(0)\r\n",
        "        correct += (predicted == labels).sum().item()\r\n",
        "    return 100 * correct / total\r\n",
        "\r\n",
        "def train_one_pass(p_network, criterion, p_optim, trainloader, epoch=1, log_interval=100, print_log=True):\r\n",
        "    p_network.train()\r\n",
        "    acc_one_pass, loss_one_pass = [], []\r\n",
        "    for idx, (images, labels) in enumerate(trainloader):\r\n",
        "        # Move tensors to the configured device\r\n",
        "        images = images.reshape(-1, 28*28).to(device) # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\r\n",
        "        labels = labels.to(device)\r\n",
        "        \r\n",
        "        # Forward pass\r\n",
        "        model_out = p_network(images)\r\n",
        "        loss = criterion(model_out, labels) # Get loss using outputs and ground truth labels.\r\n",
        "        \r\n",
        "        # Backprpagation and optimization\r\n",
        "        p_optim.zero_grad() # remember to clear grads before calling gradients\r\n",
        "        loss.backward() # Call backward on the loss ()\r\n",
        "        p_optim.step() # Call optimizer.step to perform SGD update.\r\n",
        "        \r\n",
        "        acc = cal_acc(model_out, labels) # Print the accuracy, loss and amount of data used till now.\r\n",
        "\r\n",
        "        # Print Information\r\n",
        "        if print_log and (idx + 1) % log_interval == 0 :\r\n",
        "            print('Iter: [{}/{} ({:.2f}%)] \\t Train Loss: {:.4f} \\t Train Accuracy: {:.2f}%'.format(\r\n",
        "                (idx+1) * len(images), len(trainset), \r\n",
        "                100.*(idx+1) * len(images)/len(trainset), loss, acc))\r\n",
        "        acc_one_pass.append(acc)\r\n",
        "        loss_one_pass.append(loss)\r\n",
        "    \r\n",
        "    avg_acc = sum(acc_one_pass) / len(acc_one_pass)\r\n",
        "    avg_loss = sum(loss_one_pass) / len(loss_one_pass)\r\n",
        "    print('Train on Epoch: {} \\t Loss: {:.4f} \\t Accuracy: {:.2f}%'.format(\r\n",
        "        epoch, avg_loss, avg_acc).center(76, '='))\r\n",
        "\r\n",
        "\r\n",
        "def test_one_pass(p_network, testloader, epoch=1):\r\n",
        "    p_network.eval()\r\n",
        "    loss_lst, acc_lst = [], []\r\n",
        "    with torch.no_grad():\r\n",
        "        for images, labels in testloader:\r\n",
        "            images = images.reshape(-1, 28*28).to(device) # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\r\n",
        "            labels = labels.to(device)\r\n",
        "            model_out = p_network(images)\r\n",
        "            loss = criterion(model_out, labels)\r\n",
        "            acc = cal_acc(model_out, labels)\r\n",
        "            loss_lst.append(loss)\r\n",
        "            acc_lst.append(acc)\r\n",
        "    loss = sum(loss_lst) / len(loss_lst)\r\n",
        "    acc = sum(acc_lst) / len(acc_lst)\r\n",
        "    print('Test on Epoch: {} \\t Loss: {:.4f} \\t Accuracy: {:.2f}%'.format(\r\n",
        "        epoch, loss, acc).center(76, '='))\r\n",
        "\r\n",
        "network = Model().to(device)\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.01, momentum=momentum) \r\n",
        "\r\n",
        "# Train the model\r\n",
        "train_one_pass(network, criterion, optimizer, trainloader,\r\n",
        "               print_log=True)\r\n",
        "\r\n",
        "# Test the model\r\n",
        "test_one_pass(network, testloader)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iter: [6400/60000 (10.67%)] \t Train Loss: 2.1593 \t Train Accuracy: 25.00%\n",
            "Iter: [12800/60000 (21.33%)] \t Train Loss: 1.7328 \t Train Accuracy: 60.94%\n",
            "Iter: [19200/60000 (32.00%)] \t Train Loss: 1.0976 \t Train Accuracy: 73.44%\n",
            "Iter: [25600/60000 (42.67%)] \t Train Loss: 0.8410 \t Train Accuracy: 76.56%\n",
            "Iter: [32000/60000 (53.33%)] \t Train Loss: 0.5348 \t Train Accuracy: 85.94%\n",
            "Iter: [38400/60000 (64.00%)] \t Train Loss: 0.5384 \t Train Accuracy: 87.50%\n",
            "Iter: [44800/60000 (74.67%)] \t Train Loss: 0.5174 \t Train Accuracy: 89.06%\n",
            "Iter: [51200/60000 (85.33%)] \t Train Loss: 0.4137 \t Train Accuracy: 90.62%\n",
            "Iter: [57600/60000 (96.00%)] \t Train Loss: 0.4672 \t Train Accuracy: 82.81%\n",
            "============Train on Epoch: 1 \t Loss: 1.0140 \t Accuracy: 71.86%=============\n",
            "=============Test on Epoch: 1 \t Loss: 0.4364 \t Accuracy: 87.38%=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBLLqaCWH_sY"
      },
      "source": [
        "\n",
        "Q6. (Multiple Passes of Data) Write a loop to perform the training pass for 50 training iterations (50 epochs, this is outer for loop of data loader). Print and save accuracy and loss after each epoch.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sy0JoCSziO5t",
        "outputId": "10fa29be-2d6a-4125-a33b-ae4ac23f58a6"
      },
      "source": [
        "def multiple_pass(model, criterion, optimizer, train_loader, testloader, \r\n",
        "                  num_epochs=10, log_interval=300, print_log=False):\r\n",
        "    # Train the model\r\n",
        "    total_step = len(train_loader)\r\n",
        "    for epoch in range(1, num_epochs + 1):\r\n",
        "        train_one_pass(model, criterion, optimizer, train_loader, \r\n",
        "                       epoch=epoch, log_interval=log_interval, print_log=print_log)\r\n",
        "        test_one_pass(model, testloader, \r\n",
        "                      epoch=epoch)\r\n",
        "\r\n",
        "network = Model().to(device)\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.SGD(network.parameters(), lr=0.01, momentum=momentum) \r\n",
        "\r\n",
        "# Train and Test\r\n",
        "multiple_pass(network, criterion, optimizer, trainloader, testloader,\r\n",
        "              num_epochs=10, print_log=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============Train on Epoch: 1 \t Loss: 1.0609 \t Accuracy: 71.19%=============\n",
            "=============Test on Epoch: 1 \t Loss: 0.4451 \t Accuracy: 87.10%=============\n",
            "============Train on Epoch: 2 \t Loss: 0.3902 \t Accuracy: 88.74%=============\n",
            "=============Test on Epoch: 2 \t Loss: 0.3473 \t Accuracy: 89.54%=============\n",
            "============Train on Epoch: 3 \t Loss: 0.3303 \t Accuracy: 90.40%=============\n",
            "=============Test on Epoch: 3 \t Loss: 0.3143 \t Accuracy: 90.34%=============\n",
            "============Train on Epoch: 4 \t Loss: 0.2992 \t Accuracy: 91.24%=============\n",
            "=============Test on Epoch: 4 \t Loss: 0.2834 \t Accuracy: 91.97%=============\n",
            "============Train on Epoch: 5 \t Loss: 0.2746 \t Accuracy: 91.96%=============\n",
            "=============Test on Epoch: 5 \t Loss: 0.2552 \t Accuracy: 92.79%=============\n",
            "============Train on Epoch: 6 \t Loss: 0.2525 \t Accuracy: 92.64%=============\n",
            "=============Test on Epoch: 6 \t Loss: 0.2397 \t Accuracy: 93.02%=============\n",
            "============Train on Epoch: 7 \t Loss: 0.2329 \t Accuracy: 93.17%=============\n",
            "=============Test on Epoch: 7 \t Loss: 0.2212 \t Accuracy: 93.50%=============\n",
            "============Train on Epoch: 8 \t Loss: 0.2150 \t Accuracy: 93.75%=============\n",
            "=============Test on Epoch: 8 \t Loss: 0.2151 \t Accuracy: 93.66%=============\n",
            "============Train on Epoch: 9 \t Loss: 0.1986 \t Accuracy: 94.24%=============\n",
            "=============Test on Epoch: 9 \t Loss: 0.1901 \t Accuracy: 94.29%=============\n",
            "============Train on Epoch: 10 \t Loss: 0.1838 \t Accuracy: 94.70%============\n",
            "============Test on Epoch: 10 \t Loss: 0.1817 \t Accuracy: 94.54%=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhIF4yegIBxb"
      },
      "source": [
        "\n",
        "Q7. Play around with the momentum of the SGD optimizer and then replace the SGD optimizer with Adam and RMSProp and analyze the loss trajectory (save the value of loss in an array after each update) of 50 training iterations for each of these types of optimizers. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pke4C-BpIDKc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8bc5877-50ef-4de5-a925-b394f29f849c"
      },
      "source": [
        "network = Model().to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "adam_optim = torch.optim.Adam(network.parameters(), lr=0.01) \n",
        "\n",
        "# Train and Test\n",
        "multiple_pass(network, criterion, adam_optim, trainloader, testloader,\n",
        "              num_epochs=10, print_log=False)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============Train on Epoch: 1 \t Loss: 0.3965 \t Accuracy: 87.51%=============\n",
            "=============Test on Epoch: 1 \t Loss: 0.3494 \t Accuracy: 87.87%=============\n",
            "============Train on Epoch: 2 \t Loss: 0.2534 \t Accuracy: 92.53%=============\n",
            "=============Test on Epoch: 2 \t Loss: 0.2042 \t Accuracy: 93.89%=============\n",
            "============Train on Epoch: 3 \t Loss: 0.2371 \t Accuracy: 93.18%=============\n",
            "=============Test on Epoch: 3 \t Loss: 0.1931 \t Accuracy: 94.36%=============\n",
            "============Train on Epoch: 4 \t Loss: 0.2271 \t Accuracy: 93.40%=============\n",
            "=============Test on Epoch: 4 \t Loss: 0.2243 \t Accuracy: 93.25%=============\n",
            "============Train on Epoch: 5 \t Loss: 0.2227 \t Accuracy: 93.74%=============\n",
            "=============Test on Epoch: 5 \t Loss: 0.3473 \t Accuracy: 91.66%=============\n",
            "============Train on Epoch: 6 \t Loss: 0.2191 \t Accuracy: 93.80%=============\n",
            "=============Test on Epoch: 6 \t Loss: 0.2355 \t Accuracy: 93.55%=============\n",
            "============Train on Epoch: 7 \t Loss: 0.2144 \t Accuracy: 94.08%=============\n",
            "=============Test on Epoch: 7 \t Loss: 0.2024 \t Accuracy: 94.60%=============\n",
            "============Train on Epoch: 8 \t Loss: 0.2062 \t Accuracy: 94.39%=============\n",
            "=============Test on Epoch: 8 \t Loss: 0.2517 \t Accuracy: 93.74%=============\n",
            "============Train on Epoch: 9 \t Loss: 0.2056 \t Accuracy: 94.37%=============\n",
            "=============Test on Epoch: 9 \t Loss: 0.2631 \t Accuracy: 93.48%=============\n",
            "============Train on Epoch: 10 \t Loss: 0.1968 \t Accuracy: 94.64%============\n",
            "============Test on Epoch: 10 \t Loss: 0.2687 \t Accuracy: 93.33%=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGKzJ3b3ID6h"
      },
      "source": [
        "\n",
        "Q8. Play around with the initialization function like uniform and gaussian learnt in the lecture slides.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xoeVDWqZolb",
        "outputId": "d8120c21-b142-454c-e693-7214a2de1df3"
      },
      "source": [
        "def init_weights_uniform(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Linear') != -1:\n",
        "        m.weight.data.uniform_(0.0, 1.0) # uniform distribution(bias=0)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "# Initialize Weight\n",
        "network_initialized = Model().to(device)\n",
        "network_initialized.apply(init_weights_uniform)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "adam_optim = torch.optim.Adam(network_initialized.parameters(), lr=0.01) \n",
        "\n",
        "# Train and Test\n",
        "print(\"Now running the uniformed initialized model with Adam Optimizer\")\n",
        "multiple_pass(network_initialized, criterion, adam_optim, trainloader, testloader,\n",
        "              num_epochs=10, print_log=False)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now running the uniformed initialized model with Adam Optimizer\n",
            "============Train on Epoch: 1 \t Loss: 2.3023 \t Accuracy: 11.01%=============\n",
            "=============Test on Epoch: 1 \t Loss: 2.3013 \t Accuracy: 10.26%=============\n",
            "============Train on Epoch: 2 \t Loss: 2.3021 \t Accuracy: 11.04%=============\n",
            "=============Test on Epoch: 2 \t Loss: 2.3014 \t Accuracy: 11.33%=============\n",
            "============Train on Epoch: 3 \t Loss: 2.3021 \t Accuracy: 11.05%=============\n",
            "=============Test on Epoch: 3 \t Loss: 2.3023 \t Accuracy: 11.33%=============\n",
            "============Train on Epoch: 4 \t Loss: 2.3021 \t Accuracy: 11.11%=============\n",
            "=============Test on Epoch: 4 \t Loss: 2.3022 \t Accuracy: 10.26%=============\n",
            "============Train on Epoch: 5 \t Loss: 2.3021 \t Accuracy: 11.02%=============\n",
            "=============Test on Epoch: 5 \t Loss: 2.3016 \t Accuracy: 11.30%=============\n",
            "============Train on Epoch: 6 \t Loss: 2.3022 \t Accuracy: 10.97%=============\n",
            "=============Test on Epoch: 6 \t Loss: 2.3016 \t Accuracy: 11.33%=============\n",
            "============Train on Epoch: 7 \t Loss: 2.3021 \t Accuracy: 11.08%=============\n",
            "=============Test on Epoch: 7 \t Loss: 2.3013 \t Accuracy: 11.36%=============\n",
            "============Train on Epoch: 8 \t Loss: 2.3022 \t Accuracy: 11.05%=============\n",
            "=============Test on Epoch: 8 \t Loss: 2.3013 \t Accuracy: 11.39%=============\n",
            "============Train on Epoch: 9 \t Loss: 2.3023 \t Accuracy: 11.09%=============\n",
            "=============Test on Epoch: 9 \t Loss: 2.3013 \t Accuracy: 11.33%=============\n",
            "============Train on Epoch: 10 \t Loss: 2.3022 \t Accuracy: 10.99%============\n",
            "============Test on Epoch: 10 \t Loss: 2.3020 \t Accuracy: 10.26%=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntNK9TIooIy7",
        "outputId": "6daf0f29-716d-44c1-af31-043a23340240"
      },
      "source": [
        "def weights_init_normal(m):\r\n",
        "        classname = m.__class__.__name__\r\n",
        "        if classname.find('Linear') != -1:\r\n",
        "            y = m.in_features\r\n",
        "            m.weight.data.normal_(0.0,1/np.sqrt(y))\r\n",
        "            m.bias.data.fill_(0)\r\n",
        "\r\n",
        "# Initialize Weight\r\n",
        "network_initialized = Model().to(device)\r\n",
        "network_initialized.apply(weights_init_normal)\r\n",
        "\r\n",
        "# Loss and optimizer\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "adam_optim = torch.optim.Adam(network_initialized.parameters(), lr=0.01) \r\n",
        "\r\n",
        "# Train and Test\r\n",
        "print(\"Now running the normal distribution initialized model with Adam Optimizer\")\r\n",
        "multiple_pass(network_initialized, criterion, adam_optim, trainloader, testloader,\r\n",
        "              num_epochs=10, print_log=False)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now running the normal distribution initialized model with Adam Optimizer\n",
            "============Train on Epoch: 1 \t Loss: 0.3861 \t Accuracy: 88.38%=============\n",
            "=============Test on Epoch: 1 \t Loss: 0.2470 \t Accuracy: 92.66%=============\n",
            "============Train on Epoch: 2 \t Loss: 0.2371 \t Accuracy: 92.98%=============\n",
            "=============Test on Epoch: 2 \t Loss: 0.2019 \t Accuracy: 94.34%=============\n",
            "============Train on Epoch: 3 \t Loss: 0.2304 \t Accuracy: 93.42%=============\n",
            "=============Test on Epoch: 3 \t Loss: 0.2073 \t Accuracy: 94.28%=============\n",
            "============Train on Epoch: 4 \t Loss: 0.2173 \t Accuracy: 93.98%=============\n",
            "=============Test on Epoch: 4 \t Loss: 0.2081 \t Accuracy: 94.53%=============\n",
            "============Train on Epoch: 5 \t Loss: 0.2120 \t Accuracy: 94.17%=============\n",
            "=============Test on Epoch: 5 \t Loss: 0.2518 \t Accuracy: 93.31%=============\n",
            "============Train on Epoch: 6 \t Loss: 0.2078 \t Accuracy: 94.28%=============\n",
            "=============Test on Epoch: 6 \t Loss: 0.2137 \t Accuracy: 94.69%=============\n",
            "============Train on Epoch: 7 \t Loss: 0.2063 \t Accuracy: 94.48%=============\n",
            "=============Test on Epoch: 7 \t Loss: 0.2237 \t Accuracy: 94.57%=============\n",
            "============Train on Epoch: 8 \t Loss: 0.1976 \t Accuracy: 94.71%=============\n",
            "=============Test on Epoch: 8 \t Loss: 0.3177 \t Accuracy: 92.05%=============\n",
            "============Train on Epoch: 9 \t Loss: 0.1945 \t Accuracy: 94.75%=============\n",
            "=============Test on Epoch: 9 \t Loss: 0.2549 \t Accuracy: 94.21%=============\n",
            "============Train on Epoch: 10 \t Loss: 0.1995 \t Accuracy: 94.72%============\n",
            "============Test on Epoch: 10 \t Loss: 0.2119 \t Accuracy: 94.79%=============\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSNwcQwcIGEG"
      },
      "source": [
        "\n",
        "Q9. Add batch normalization to each of the layers before ReLu activation function. Check how your results or iterations vary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1znPChEaWyob",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf4c46f-de58-4104-9027-52abe981fa5f"
      },
      "source": [
        "class Model_Normalization(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model_Normalization, self).__init__()\n",
        "        self.fc1 = nn.Linear(784, 128)\n",
        "        self.bn1 = nn.BatchNorm1d(num_features=128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.bn2 = nn.BatchNorm1d(num_features=64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.fc1(x)))\n",
        "        x = F.relu(self.bn2(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Initialize Weight\n",
        "network_initialized = Model_Normalization().to(device)\n",
        "network_initialized.apply(weights_init_normal)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "adam_optim = torch.optim.Adam(network_initialized.parameters(), lr=0.01) \n",
        "\n",
        "# Train and Test\n",
        "print(\"Now running the normal distribution initialized model with Adam Optimizer\")\n",
        "multiple_pass(network_initialized, criterion, adam_optim, trainloader, testloader,\n",
        "              num_epochs=10, print_log=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Now running the normal distribution initialized model with Adam Optimizer\n",
            "============Train on Epoch: 1 \t Loss: 0.2012 \t Accuracy: 93.86%=============\n",
            "=============Test on Epoch: 1 \t Loss: 0.1118 \t Accuracy: 96.39%=============\n",
            "============Train on Epoch: 2 \t Loss: 0.1057 \t Accuracy: 96.74%=============\n",
            "=============Test on Epoch: 2 \t Loss: 0.0867 \t Accuracy: 97.19%=============\n",
            "============Train on Epoch: 3 \t Loss: 0.0802 \t Accuracy: 97.44%=============\n",
            "=============Test on Epoch: 3 \t Loss: 0.0785 \t Accuracy: 97.54%=============\n",
            "============Train on Epoch: 4 \t Loss: 0.0657 \t Accuracy: 97.89%=============\n",
            "=============Test on Epoch: 4 \t Loss: 0.0849 \t Accuracy: 97.38%=============\n",
            "============Train on Epoch: 5 \t Loss: 0.0590 \t Accuracy: 98.10%=============\n",
            "=============Test on Epoch: 5 \t Loss: 0.0993 \t Accuracy: 97.08%=============\n",
            "============Train on Epoch: 6 \t Loss: 0.0503 \t Accuracy: 98.40%=============\n",
            "=============Test on Epoch: 6 \t Loss: 0.0961 \t Accuracy: 97.09%=============\n",
            "============Train on Epoch: 7 \t Loss: 0.0461 \t Accuracy: 98.50%=============\n",
            "=============Test on Epoch: 7 \t Loss: 0.0719 \t Accuracy: 97.80%=============\n",
            "============Train on Epoch: 8 \t Loss: 0.0419 \t Accuracy: 98.60%=============\n",
            "=============Test on Epoch: 8 \t Loss: 0.0781 \t Accuracy: 97.95%=============\n",
            "============Train on Epoch: 9 \t Loss: 0.0367 \t Accuracy: 98.77%=============\n",
            "=============Test on Epoch: 9 \t Loss: 0.0816 \t Accuracy: 97.62%=============\n",
            "============Train on Epoch: 10 \t Loss: 0.0338 \t Accuracy: 98.81%============\n",
            "============Test on Epoch: 10 \t Loss: 0.0799 \t Accuracy: 97.80%=============\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}