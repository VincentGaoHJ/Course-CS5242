{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "practice1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VincentGaoHJ/Course-CS5242/blob/master/practice1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQPEquNwnR1_"
      },
      "source": [
        "## PYTORCH TENSORS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lR05D7BXo9UV"
      },
      "source": [
        "WHAT IS PYTORCH?\n",
        "It’s a Python-based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "- A replacement for NumPy to use the power of GPUs\n",
        "- A deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "**Tensors**\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuHI9cGDvNaP"
      },
      "source": [
        "# Run some setup code for this notebook.\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
        "# rather than in a new window.\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# Some more magic so that the notebook will reload external python modules;\n",
        "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3SsL75JYrsK",
        "outputId": "06cc1dd1-7b00-4bd8-af51-398f18e16045"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue Jan 19 06:43:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    27W / 250W |     10MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeGWK1afYBIy",
        "outputId": "02c19bcd-0490-4df7-9548-db8e9c09739c"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "device"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXVqMj2SUzA6"
      },
      "source": [
        "Q1. Create a tensor “a” initialized from the list [2, 5, 8, 9]. Now print attributes of tensor  “a” i.e shape, dtype, device. Convert it to Numpy array “e”. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLOvK7mapC0H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3114cac8-1bdf-47ff-e51a-4df5638effde"
      },
      "source": [
        "tensor_lst = [2, 5, 8, 9]\n",
        "a = torch.tensor(tensor_lst)\n",
        "print(a)\n",
        "print(\"shape: \", a.shape)\n",
        "print(\"dtype: \", a.dtype)\n",
        "print(\"device: \", a.device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([2, 5, 8, 9])\n",
            "shape:  torch.Size([4])\n",
            "dtype:  torch.int64\n",
            "device:  cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCLUVWarsxJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22654f23-f9a0-4ec2-f70b-7cc4cf495e24"
      },
      "source": [
        "e = a.numpy()\n",
        "print(e)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2 5 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUDKczOZVJbN"
      },
      "source": [
        "Q2. Create a tensor “b” of size 4 * 5 initialized with all 0’s. Add 2 to “b”. Create another tensor “c” of the exact same as “b” initialized with all ones. Now create tensor “d = b + c”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1VS_ed6s8k7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c405289-4d22-4f6c-d9cd-63ed4249063f"
      },
      "source": [
        "b = torch.from_numpy(np.zeros(20).reshape(4,5)) + 2\n",
        "c = torch.from_numpy(np.ones(20).reshape(4,5))\n",
        "d = b + c\n",
        "print(d)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3., 3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3., 3.],\n",
            "        [3., 3., 3., 3., 3.]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pa2A2x8XVSa0"
      },
      "source": [
        "Q3. Create a Numpy array “f” of size 5 * 4 initialized with random numbers. Convert it to tensor “g”. Create “h” similar to “f” with random numbers. Transpose “h” and do matrix multiplication of “h” and “f”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRv-YJcHqyv2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16a8fe2f-2f33-4a2b-d860-9cc02a3c2b72"
      },
      "source": [
        "g, h = torch.from_numpy(np.random.rand(5,4)), torch.from_numpy(np.random.rand(5,4)).T\n",
        "print('g:\\n', g)\n",
        "print('h:\\n', h)\n",
        "mm = torch.mm(g, h)\n",
        "print('Matrix Multiplication g and h:\\n',mm)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "g:\n",
            " tensor([[0.1071, 0.3332, 0.0938, 0.2670],\n",
            "        [0.8479, 0.4214, 0.3424, 0.3535],\n",
            "        [0.9303, 0.9219, 0.8716, 0.1133],\n",
            "        [0.5411, 0.8381, 0.1268, 0.8899],\n",
            "        [0.7038, 0.1308, 0.2497, 0.8991]], dtype=torch.float64)\n",
            "h:\n",
            " tensor([[0.7033, 0.5332, 0.8922, 0.8155, 0.0076],\n",
            "        [0.5811, 0.3470, 0.5627, 0.8642, 0.6107],\n",
            "        [0.2847, 0.4374, 0.2984, 0.9952, 0.2905],\n",
            "        [0.8636, 0.4985, 0.5921, 0.0458, 0.8609]], dtype=torch.float64)\n",
            "Matrix Multiplication g and h:\n",
            " tensor([[0.5262, 0.3468, 0.4691, 0.4809, 0.4614],\n",
            "        [1.2439, 0.9243, 1.3051, 1.4126, 0.6676],\n",
            "        [1.5359, 1.2536, 1.6759, 2.4280, 0.9208],\n",
            "        [1.6721, 1.0784, 1.5190, 1.3326, 1.3188],\n",
            "        [1.4184, 0.9780, 1.3083, 0.9766, 0.9317]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OGOS7DnzlT3"
      },
      "source": [
        "Q4. Deep Learning is based on artificial neural networks which are typically built with units called \"neurons”. Each neuron has some number of weighted inputs. These weighted inputs are summed together then passed through an activation function to get the unit's output.\n",
        "\t\n",
        "1. Define a 1-D tensor “X” containing numbers from 1 to 5.\n",
        "2. Define a 1-D tensor “W1” containing 5 random weights.\n",
        "3. Define a tensor “b” contained 1 random weight.\n",
        "4. Compute tensor “H = X * W1 + b” using pytorch. (Note the shape of tensors)\n",
        "5. Apply sigmoid activation function to calculate the “Y”, such that “Y = 1 / (1 + exp(-H))”\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBCEPd-kuN7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b04612f1-022e-44dd-b381-11a3c7c87584"
      },
      "source": [
        "a.to(torch.device('cpu:0'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2, 5, 8, 9])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oa8evoHguZ4",
        "outputId": "9a14fb2b-40d7-4705-df29-aaec198781ea"
      },
      "source": [
        "# Define a 1-D tensor 'X' containing numbers from 1 to 5.\r\n",
        "X = torch.tensor([range(1,6)]).float()\r\n",
        "print(\"X:\\n\", X)\r\n",
        "\r\n",
        "# Define a 1-D tensor \"W1\" containing 5 random weights.\r\n",
        "W1 = torch.randn(1, 5)\r\n",
        "print(\"W1:\\n\", W1)\r\n",
        "\r\n",
        "# Define a tensor “b” contained 1 random weight.\r\n",
        "b = torch.from_numpy(np.random.rand(1))\r\n",
        "print(\"b:\\n\", b)\r\n",
        "\r\n",
        "# Compute tensor “H = X * W1 + b” using pytorch. (Note the shape of tensors)\r\n",
        "H = torch.mm(X, torch.transpose(W1, 0, 1)) + b\r\n",
        "print(\"H = X * W1 + b:\\n\", H)\r\n",
        "\r\n",
        "# Apply sigmoid activation function to calculate the “Y”, such that “Y = 1 / (1 + exp(-H))”\r\n",
        "Y = 1 / (1 + torch.exp(-H))\r\n",
        "print(\"Y = 1 / (1 + exp(-H)):\\n\", Y)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X:\n",
            " tensor([[1., 2., 3., 4., 5.]])\n",
            "W1:\n",
            " tensor([[-0.3698,  0.9089,  0.5203, -0.6826, -0.9009]])\n",
            "b:\n",
            " tensor([0.2028], dtype=torch.float64)\n",
            "H = X * W1 + b:\n",
            " tensor([[-4.0230]], dtype=torch.float64)\n",
            "Y = 1 / (1 + exp(-H)):\n",
            " tensor([[0.0176]], dtype=torch.float64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NeFRFfJtVAZ"
      },
      "source": [
        "**You have just coded to write a neuron !!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZijA-qu8vqz"
      },
      "source": [
        "Q5. Adding multiple neurons in a single layer (3 Hidden Units)\n",
        "1. Define 2-D tensor “W2” containing random numbers of shape 5 * 3\n",
        "2. Define 1-D tensor of “b2” containing 3 random numbers.\n",
        "3. Compute tensor H2 = [h1 h2 h3] using the “H2 = X * W2 + b2” using pytorch\n",
        "4. Apply sigmoid activation function to calculate “Y2 = [y1 y2 y3]” such that “Y = 1 / (1 + exp(-H2)”\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xExsfWQQK6Yw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "2379a471-e5bf-4534-e2a1-30afb0659c2a"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W2 = \n",
            " tensor([[-1.2390,  0.2733,  0.4978],\n",
            "        [-1.4140, -0.5967,  1.9397],\n",
            "        [ 0.9528, -0.8102,  1.1685],\n",
            "        [ 1.0026,  0.9184, -1.2489],\n",
            "        [ 0.2120,  0.8592, -0.4685]])\n",
            "b2 = \n",
            " tensor([ 0.7799, -0.4821, -0.6722])\n",
            "Tensor H =  tensor([ 4.6419,  4.1368, -0.1276])\n",
            "Tensor Y =  tensor([0.9905, 0.9843, 0.4681])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYNx84SOtd-b"
      },
      "source": [
        "**Now there are 3 neurons outputs!!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9ZvEMtpL96g"
      },
      "source": [
        "Q6.  Stacking one neuron on top of others. The real power of a neural network comes when we apply one function on top of others. ( 3 output units)\n",
        "1. Define 2-D tensor “W21” containing random numbers of shape 3 * 3\n",
        "2. Define 1-D tensor “b3” containing 3 random number\n",
        "3. Compute “H3 = W21 * Y2 + b”. Compute the expected shape of H3.\n",
        "4. Apply softmax pytorch activation function to H3.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CGHA1vkXMFGj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "7b906112-4f85-4668-bc02-297419c6c9c9"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y3 obtained after softmax = tensor([0.1498, 0.6191, 0.2311])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjns7H0HBC59"
      },
      "source": [
        "**Now there are 3 neurons outputs!!**"
      ]
    }
  ]
}